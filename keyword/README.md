# 코드 설명 & Work Flow

token1.py --> /share/ 폴더에 있는 상담데이터 불러와서 1.전처리하고 2.명사만 추출해서 3.빈도수세고 4.한번나온것들, 한글자짜리 단어들 불용어 리스트에 추가하고 5.원본문장,명사로 자른문장을 문서별로 파일로 저장하고 단어와 불용어리스트도 역시 파일로 저장

token2.py --> 문서의 문장들에서 불용어는 이 단계에서 제거. 위에서 저장한 불용어 리스트와 명사단위로 자른 문장들을 load해서 문장 내 해당단어가 있는지 체크하고 있으면 뺀 후 다시 새로 저장.

master.py --> 이 스크립트에서 전체 스크립트를 관리하려고 했으나 일단 틀만 만들어둠. 현재 사용하는 건 token2.py 를 4개 스레드를 이용해 작업할 수 있게 프로세스 여러개 생성해서 돌리는 기능. 

token3.py --> master.py에서 분할해서 작업한 스크립트를 하나의 파일로 merge하는 기능. (추후 다른 스크립트랑 통합할 예정)

tfidf.py --> 문서에서 나온 단어의 tf값과 df값을 바탕으로 단어별로 tf-idf값을 구하고 그 값들을 파일로 저장

bayes.py --> 단어의 가중치를 구하는 코드. 어떤 두 단어가 동시에 출현했을때 가중치를 올리는데 이럴 경우 단어 빈도가 높은 값이 가중치가 높게됨. 값을 normalize하기 위해 idf값을 곱해주어 다른 문서에서 잘 나오지 않는 단어의 가중치를 높여줌.

tag.py --> 위 스크립트들에서 생성된 파일들을 바탕으로 문서마다 가중치가 높은 키워드들을 뽑아내줌.
